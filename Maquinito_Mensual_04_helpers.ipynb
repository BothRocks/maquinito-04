{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e2O4uXnhTya"
      },
      "source": [
        "# Donde viven los monstruos - Helpers\n",
        "## Maquinito Mensual 04"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NLBlDaLyUKDe"
      },
      "outputs": [],
      "source": [
        "#@markdown #Comprobar GPU\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "--WwpUMfIYrX",
        "outputId": "0344e04f-7965-413e-e8d7-75480856e667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301,
          "referenced_widgets": [
            "2c855feef5b942e5aae279fe07ee5d66",
            "91d8536d300542b0835cd28e9335294f",
            "ef73edfcfe974698afea1f7675a7e10c",
            "e731f8c1fdac4bd49fb1bb50f662e803",
            "ba5667fd3b5b470193c976278a7627c7",
            "8a6bd3466bdd4527bda4e0dbd91dbb69",
            "bacd102d0ee4446b947a151c7551f9e4",
            "cdb060447487475ebe9d53f10be71818",
            "1ccb818fe00a478393f4668015d5672e",
            "359f08cab7cf4a3b948f082f7fe03045",
            "bafd8dc21ae8454895feac087afe800f",
            "6c709b5a1a5044c48d1df071ad0e8759",
            "802c20d6027b4e6081b236f60a77c862",
            "faf229f87a614803ab7a71eab25571bc"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Login successful\n",
            "Your token has been saved to /root/.huggingface/token\n"
          ]
        }
      ],
      "source": [
        "#@markdown #Login en HuggingFace\n",
        "from IPython.display import clear_output\n",
        "!pip install huggingface_hub\n",
        "from huggingface_hub import notebook_login\n",
        "clear_output()\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "9vzfOZ27UsTm"
      },
      "outputs": [],
      "source": [
        "#@markdown #Librerías + Modelos + Funciones de ayuda\n",
        "\n",
        "!pip install diffusers==0.3.0\n",
        "!pip install transformers scipy ftfy\n",
        "\n",
        "from google.colab import files\n",
        "from transformers import CLIPTextModel, CLIPTokenizer\n",
        "from tqdm.auto import tqdm\n",
        "from torch import autocast\n",
        "from PIL import Image\n",
        "from huggingface_hub import notebook_login\n",
        "from diffusers import AutoencoderKL, UNet2DConditionModel, LMSDiscreteScheduler\n",
        "from torchvision import transforms as tfms\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "clear_output()\n",
        "\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(\n",
        "    \"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\", use_auth_token=True)\n",
        "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "unet = UNet2DConditionModel.from_pretrained(\n",
        "    \"CompVis/stable-diffusion-v1-4\", subfolder=\"unet\", use_auth_token=True)\n",
        "scheduler = LMSDiscreteScheduler(\n",
        "    beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\n",
        "clear_output()\n",
        "\n",
        "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "vae = vae.to(torch_device)\n",
        "text_encoder = text_encoder.to(torch_device)\n",
        "unet = unet.to(torch_device)\n",
        "\n",
        "to_tensor_tfm = tfms.ToTensor() \n",
        "\n",
        "\n",
        "def pil_to_latent(input_im):\n",
        "  with torch.no_grad():\n",
        "    pixel_values = to_tensor_tfm(input_im).unsqueeze(0).to(torch_device)*2-1\n",
        "    latents = vae.encode(pixel_values).latent_dist.sample().detach()\n",
        "    latents = latents * 0.18215\n",
        "  return latents\n",
        "\n",
        "\n",
        "def latents_to_pil(latents):\n",
        "    latents = (1 / 0.18215) * latents\n",
        "    with torch.no_grad():\n",
        "        images = vae.decode(latents).sample\n",
        "    images = (images / 2 + 0.5).clamp(0, 1)\n",
        "    images = images.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
        "    images = (images * 255).round().astype(\"uint8\")\n",
        "    pil_images = [Image.fromarray(image) for image in images]\n",
        "\n",
        "    return pil_images\n",
        "\n",
        "\n",
        "def image_grid(imgs, cols):\n",
        "    grid_w = min([cols, len(imgs)])\n",
        "    grid_h = len(imgs)//cols + 1\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(grid_w*w, grid_h*h))\n",
        "    #grid_w, grid_h = grid.size\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i % cols*w, i//cols*h))\n",
        "\n",
        "    return grid\n",
        "\n",
        "\n",
        "def render(steps, scale, seed, embeddings, batch_size):\n",
        "\n",
        "    width = 512\n",
        "    height = 512\n",
        "\n",
        "    if seed == 0:\n",
        "      seed = torch.randint(2**32, (1, 1))[0, 0].item()\n",
        "\n",
        "    scheduler.set_timesteps(steps)\n",
        "    generator = torch.manual_seed(seed)\n",
        "\n",
        "    latents = torch.randn(\n",
        "        (batch_size, unet.in_channels, height // 8, width // 8),\n",
        "        generator=generator,\n",
        "    )\n",
        "    latents = latents.to(torch_device)  # [batch_size, 4, 64, 64]\n",
        "    latents = latents * scheduler.sigmas[0]\n",
        "\n",
        "    with autocast(\"cuda\"):\n",
        "\n",
        "        for i, t in tqdm(enumerate(scheduler.timesteps), total=steps):\n",
        "\n",
        "            sigma = scheduler.sigmas[i]\n",
        "            latent_model_input = torch.cat(\n",
        "                [latents] * 2)  # [batch_size*2, 4, 64, 64]\n",
        "            latent_model_input = latent_model_input / ((sigma**2 + 1) ** 0.5)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # [2, 4, 64, 64]\n",
        "                noise_pred = unet(latent_model_input, t,\n",
        "                                  encoder_hidden_states=embeddings).sample\n",
        "\n",
        "            noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
        "            noise_pred = noise_pred_uncond + scale * \\\n",
        "                (noise_pred_text - noise_pred_uncond)  # [1, 4, 64, 64]\n",
        "\n",
        "            latents = scheduler.step(\n",
        "                noise_pred, i, latents).prev_sample  # [1, 4, 64, 64]\n",
        "            # print(f\"i={i} t={t}, sigma={sigma}\")\n",
        "\n",
        "    return latents_to_pil(latents), seed\n",
        "\n",
        "\n",
        "token_EOS_value = 49407\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Imagen: Espacio latente\n",
        "!curl --output peluche.jpg 'https://both.rocks/maquimensu04/peluche.jpg'\n",
        "input_image = Image.open('peluche.jpg')\n",
        "\n",
        "encoded = pil_to_latent(input_image)\n",
        "decoded = latents_to_pil(encoded)[0]\n",
        "\n",
        "decoded"
      ],
      "metadata": {
        "id": "z4FriJttLA9W",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Imagen: Sustituir por ruido\n",
        "encoded_random = encoded.clone()\n",
        "encoded_random [0,0,:,:16] = torch.rand((1,64,16))\n",
        "encoded_random [0,1,:,16:32] = torch.rand((1,64,16))\n",
        "encoded_random [0,2,:,32:48] = torch.rand((1,64,16))\n",
        "encoded_random [0,3,:,48:] = torch.rand((1,64,16))\n",
        "decoded = latents_to_pil(encoded_random)[0]\n",
        "decoded"
      ],
      "metadata": {
        "id": "1S-LE47ibSK6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Texto: Cuentatokens\n",
        "prompt1 = \"elefante\"  # @param {type:\"string\"}\n",
        "prompt2 = \"\\\"p\\xE1jaro\\\"\"  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "def tokens_to_list(tokens):\n",
        "  tokens = list(filter(lambda id: id != 49406 and id != 49407, tokens))\n",
        "  token_list = [tokenizer.decoder.get(t) for t in tokens]\n",
        "  return token_list\n",
        "\n",
        "\n",
        "tokens = tokenizer([prompt1, prompt2], return_tensors=\"np\",\n",
        "                   padding=True).input_ids\n",
        "tokens = [tokens_to_list(tokens[0]), tokens_to_list(tokens[1])]\n",
        "print(f\"{tokens[0]}: {len(tokens[0])}\")\n",
        "print(f\"{tokens[1]}: {len(tokens[1])}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3Qhz5hWMNOMS",
        "outputId": "d61185ac-291d-4e55-90c0-d23dbfb3d56c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ele', 'fan', 'te</w>']: 3\n",
            "['p', 'Ã¡', 'jaro</w>']: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Texto: Interpolación de tokens (inglés)\n",
        "def clean_tokens(tokens):\n",
        "  return list(filter(lambda id: id != 49406 and id != 49407, tokens))\n",
        "\n",
        "start_prompt = \"cat\"\n",
        "end_prompt = \"dog\"\n",
        "\n",
        "tokens = tokenizer([start_prompt, end_prompt], padding=\"max_length\",\n",
        "                   truncation=True, return_tensors=\"np\").input_ids\n",
        "\n",
        "start_token = clean_tokens(tokens[0])\n",
        "end_token = clean_tokens(tokens[1])\n",
        "\n",
        "                  \n",
        "for t in np.linspace(start_token[0], end_token[0], num=6, endpoint=True):\n",
        "  print(f\"{int(t)}:{tokenizer.decoder.get(int(t))}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0bj15KnHFEbT",
        "outputId": "5f742472-e36b-4869-b64c-5e43d461c915",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2368:cat</w>\n",
            "2280:took</w>\n",
            "2192:mid\n",
            "2104:suppor\n",
            "2016:movie</w>\n",
            "1929:dog</w>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Texto: Interpolación de tokens (español)\n",
        "def clean_tokens(tokens):\n",
        "  return list(filter(lambda id: id != 49406 and id != 49407, tokens))\n",
        "\n",
        "start_prompt = \"elefante\"\n",
        "end_prompt = \"pájaro\"\n",
        "\n",
        "tokens = tokenizer([start_prompt, end_prompt], padding=\"max_length\",\n",
        "                   truncation=True, return_tensors=\"np\").input_ids\n",
        "\n",
        "start_token = clean_tokens(tokens[0])\n",
        "end_token = clean_tokens(tokens[1])\n",
        "\n",
        "print(f\"{start_prompt}: {start_token}\")\n",
        "print(f\"{end_prompt}: {end_token}\")\n",
        "                  \n",
        "for t in np.linspace(start_token[0], end_token[0], num=6, endpoint=True):\n",
        "  print(f\"{int(t)}:{tokenizer.decoder.get(int(t))}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7zDVQBgIIJUo",
        "outputId": "e60a76de-f864-4439-c9be-138752ae4583",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elefante: [2084, 1675, 756]\n",
            "pájaro: [79, 7261, 35505]\n",
            "2084:ele\n",
            "1683:hope</w>\n",
            "1282:pic</w>\n",
            "881:ster</w>\n",
            "480:Ĥ</w>\n",
            "79:p\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VgCNgAgF0Rw"
      },
      "source": [
        "### Para cuando todos tengamos máquinas súper potentes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayS_i0J6k7nF"
      },
      "outputs": [],
      "source": [
        "# #@markdown #BACKUP\n",
        "\n",
        "# num_images = 1\n",
        "\n",
        "# prompt1 = \"a cat\"  # @param {type:\"string\"}\n",
        "# prompt2 = \"a bird\"  # @param {type:\"string\"}\n",
        "\n",
        "# semilla = 25115  # @param {type:\"number\"}\n",
        "# seed = semilla\n",
        "# if seed == -1:\n",
        "#   seed = torch.randint(2**32, (1, 1))[0, 0].item()\n",
        "\n",
        "# mezcla = 0.5  # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "# mix_factor = hiperescala\n",
        "\n",
        "# height = 512\n",
        "# width = 512\n",
        "# num_inference_steps = 50\n",
        "# guidance_scale = 7.5\n",
        "\n",
        "# generator = torch.manual_seed(32)\n",
        "\n",
        "\n",
        "# text_input1 = tokenizer([prompt1], padding=\"max_length\",\n",
        "#                         max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\")\n",
        "# with torch.no_grad():\n",
        "#   text_embeddings1 = text_encoder(text_input1.input_ids.to(torch_device))[0]\n",
        "\n",
        "# text_input2 = tokenizer([prompt2], padding=\"max_length\",\n",
        "#                         max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\")\n",
        "# with torch.no_grad():\n",
        "#   text_embeddings2 = text_encoder(text_input2.input_ids.to(torch_device))[0]\n",
        "\n",
        "# # Take the average\n",
        "# # text_embeddings = text_embeddings1*mix_factor\n",
        "\n",
        "\n",
        "# # And the uncond. input as before:\n",
        "# uncond_input = tokenizer(\n",
        "#     [\"\"] * batch_size, padding=\"max_length\", max_length=77, return_tensors=\"pt\"\n",
        "# )\n",
        "# with torch.no_grad():\n",
        "#   uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[0]\n",
        "# text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n",
        "\n",
        "# # Prep Scheduler\n",
        "# scheduler.set_timesteps(num_inference_steps)\n",
        "\n",
        "# # Prep latents\n",
        "# latents_cpu = torch.randn(\n",
        "#     (batch_size, unet.in_channels, height // 8, width // 8),\n",
        "#     generator=generator,\n",
        "# )\n",
        "\n",
        "\n",
        "# # Loop\n",
        "# for f, mix_factor in enumerate(numpy.linspace(1, 2, 101)):\n",
        "\n",
        "#   text_embeddings = text_embeddings1*mix_factor\n",
        "#   text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n",
        "\n",
        "#   latents = latents_cpu.to(torch_device)\n",
        "#   latents = latents * scheduler.sigmas[0]  # Need to scale to match k\n",
        "\n",
        "#   with autocast(\"cuda\"):\n",
        "#     for i, t in tqdm(enumerate(scheduler.timesteps)):\n",
        "#       # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n",
        "#       latent_model_input = torch.cat([latents] * 2)\n",
        "#       sigma = scheduler.sigmas[i]\n",
        "#       latent_model_input = latent_model_input / ((sigma**2 + 1) ** 0.5)\n",
        "\n",
        "#       # predict the noise residual\n",
        "#       with torch.no_grad():\n",
        "#         noise_pred = unet(latent_model_input, t,\n",
        "#                           encoder_hidden_states=text_embeddings)[\"sample\"]\n",
        "\n",
        "#       # perform guidance\n",
        "#       noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
        "#       noise_pred = noise_pred_uncond + guidance_scale * \\\n",
        "#           (noise_pred_text - noise_pred_uncond)\n",
        "\n",
        "#       # compute the previous noisy sample x_t -> x_t-1\n",
        "#       latents = scheduler.step(noise_pred, i, latents)[\"prev_sample\"]\n",
        "\n",
        "#   latents_to_pil(latents)[0].save(f\"lale_{f:05d}.png\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.8.11 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "19c52f9406ed8ee88add4472b642b79c35ade567538d579e8a14fbefe9c2ac9c"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c855feef5b942e5aae279fe07ee5d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91d8536d300542b0835cd28e9335294f",
              "IPY_MODEL_ef73edfcfe974698afea1f7675a7e10c",
              "IPY_MODEL_e731f8c1fdac4bd49fb1bb50f662e803",
              "IPY_MODEL_ba5667fd3b5b470193c976278a7627c7"
            ],
            "layout": "IPY_MODEL_8a6bd3466bdd4527bda4e0dbd91dbb69"
          }
        },
        "91d8536d300542b0835cd28e9335294f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bacd102d0ee4446b947a151c7551f9e4",
            "placeholder": "​",
            "style": "IPY_MODEL_cdb060447487475ebe9d53f10be71818",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "ef73edfcfe974698afea1f7675a7e10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_1ccb818fe00a478393f4668015d5672e",
            "placeholder": "​",
            "style": "IPY_MODEL_359f08cab7cf4a3b948f082f7fe03045",
            "value": ""
          }
        },
        "e731f8c1fdac4bd49fb1bb50f662e803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_bafd8dc21ae8454895feac087afe800f",
            "style": "IPY_MODEL_6c709b5a1a5044c48d1df071ad0e8759",
            "tooltip": ""
          }
        },
        "ba5667fd3b5b470193c976278a7627c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_802c20d6027b4e6081b236f60a77c862",
            "placeholder": "​",
            "style": "IPY_MODEL_faf229f87a614803ab7a71eab25571bc",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "8a6bd3466bdd4527bda4e0dbd91dbb69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "bacd102d0ee4446b947a151c7551f9e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdb060447487475ebe9d53f10be71818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ccb818fe00a478393f4668015d5672e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "359f08cab7cf4a3b948f082f7fe03045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bafd8dc21ae8454895feac087afe800f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c709b5a1a5044c48d1df071ad0e8759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "802c20d6027b4e6081b236f60a77c862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf229f87a614803ab7a71eab25571bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}